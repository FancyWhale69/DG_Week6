{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:23:44.358039Z",
     "iopub.status.busy": "2021-08-24T19:23:44.357736Z",
     "iopub.status.idle": "2021-08-24T19:23:44.366942Z",
     "shell.execute_reply": "2021-08-24T19:23:44.365837Z",
     "shell.execute_reply.started": "2021-08-24T19:23:44.358010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py \n",
    "\n",
    "import yaml\n",
    "import gzip\n",
    "\n",
    "# READ FILE USING YAML \n",
    "def read_yaml(path):\n",
    "    \n",
    "    with open(path, 'r') as data: \n",
    "        try:\n",
    "            return yaml.safe_load(data)\n",
    "        except:\n",
    "            print(\"Something went wrong with loading the data.\")\n",
    "\n",
    "# CLEAN THE COLUMN NAMES \n",
    "def clean_col_names(df):\n",
    "\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[%\\W]', '', regex= True)\n",
    "\n",
    "# RETURN DIFFERENCE IN COLUMNS \n",
    "def col_dif(df, conf_table):\n",
    "\n",
    "    df_cols = list(df.columns)\n",
    "    ct_cols = conf_table[\"columns\"]\n",
    "    missing_from_df = list(set(ct_cols).difference(df_cols))\n",
    "    missing_from_ct = list(set(df_cols).difference(ct_cols))\n",
    "    \n",
    "    return df_cols, missing_from_df, ct_cols, missing_from_ct\n",
    "\n",
    "# CHECKS FOR THE SAME NUMBER OF COLUMNS  \n",
    "def col_val(df, conf_table):\n",
    "\n",
    "    df_cols = list(df.columns)\n",
    "    ct_cols = list(conf_table[\"columns\"])\n",
    "    df_cols_count = len(df_cols)\n",
    "    ct_cols_count = conf_table[\"num_columns\"]\n",
    "\n",
    "    if df_cols == ct_cols:\n",
    "        print(\"Validation test: PASS\")\n",
    "        return 1\n",
    "    else: \n",
    "        print(\"Validation test: FAILED\")\n",
    "        print(f\"Incoming data consists of {df_cols_count} columns.\")\n",
    "        print(f\"YAML file consists of {ct_cols_count} columns.\")\n",
    "        print(\"The listed columns are not in the incoming data: \\n{}\".format(list(set(ct_cols).difference(df_cols))))\n",
    "        print(\"The listed columns are not in the YAML file: \\n{}\".format(list(set(df_cols).difference(ct_cols))))\n",
    "        return 0 \n",
    "\n",
    "# WRITE TE FILE IN PUIPE SEPARATED TEXT FILE IN GZ FORMAT\n",
    "def write_file(df):\n",
    "\n",
    "    df.to_csv(\n",
    "        \"stocks.csv.gz\",\n",
    "        index= False,\n",
    "        sep= \"|\",\n",
    "        compression= \"gzip\"\n",
    "    )\n",
    "\n",
    "# SUMMARY OF THE DATA\n",
    "def summary(conf_table):\n",
    "\n",
    "    print(\"The file name is {}\".format(conf_table[\"path\"]))\n",
    "    print(\"The delimiter used is '{}'\".format(conf_table[\"delimiter\"]))\n",
    "    print(\"The number of columns in the data is {}\".format(conf_table[\"num_columns\"]))\n",
    "    print(\"The data is 2GB in size.\")\n",
    "    print(\"The columns for the data are: {}\".format(conf_table[\"columns\"]))\n",
    "\n",
    "# DISPLAY THE RESULTS\n",
    "def result(col_val, df, conf_table):\n",
    "\n",
    "    if col_val == 1: \n",
    "        # write the file in pip (|) separated text file\n",
    "        write_file(df)\n",
    "        # summary of the file \n",
    "        summary(conf_table)\n",
    "    else: \n",
    "        df_cols, missing_from_df, ct_cols, missing_from_ct = col_dif(df, conf_table)\n",
    "        print(\"It seems that the incoming data containing the following columns: {} \\nis missing {} \".format(df_cols,missing_from_df))\n",
    "        print(\"It seems that the YAML file containing the following columns: {} \\nis missing {} \".format(ct_cols, missing_from_ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:34:12.667841Z",
     "iopub.status.busy": "2021-08-24T19:34:12.667308Z",
     "iopub.status.idle": "2021-08-24T19:34:12.674017Z",
     "shell.execute_reply": "2021-08-24T19:34:12.673104Z",
     "shell.execute_reply.started": "2021-08-24T19:34:12.667805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing info.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile info.yaml\n",
    "\n",
    "path: stocks.csv\n",
    "delimiter: \",\"\n",
    "num_columns: 13\n",
    "columns: \n",
    "    - symbol\n",
    "    - series\n",
    "    - open\n",
    "    - high\n",
    "    - low\n",
    "    - close\n",
    "    - last\n",
    "    - prevclose\n",
    "    - tottrdqty\n",
    "    - tottrdval\n",
    "    - timestamp\n",
    "    - totaltrades\n",
    "    - isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:34:16.215945Z",
     "iopub.status.busy": "2021-08-24T19:34:16.215615Z",
     "iopub.status.idle": "2021-08-24T19:34:16.226338Z",
     "shell.execute_reply": "2021-08-24T19:34:16.225373Z",
     "shell.execute_reply.started": "2021-08-24T19:34:16.215917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'stocks.csv',\n",
       " 'delimiter': ',',\n",
       " 'num_columns': 13,\n",
       " 'columns': ['symbol',\n",
       "  'series',\n",
       "  'open',\n",
       "  'high',\n",
       "  'low',\n",
       "  'close',\n",
       "  'last',\n",
       "  'prevclose',\n",
       "  'tottrdqty',\n",
       "  'tottrdval',\n",
       "  'timestamp',\n",
       "  'totaltrades',\n",
       "  'isin']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils as u \n",
    "\n",
    "conf_table = u.read_yaml(\"info.yaml\")\n",
    "conf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:29:52.480133Z",
     "iopub.status.busy": "2021-08-24T19:29:52.479792Z",
     "iopub.status.idle": "2021-08-24T19:29:54.109071Z",
     "shell.execute_reply": "2021-08-24T19:29:54.108090Z",
     "shell.execute_reply.started": "2021-08-24T19:29:52.480103Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import dask.dataframe \n",
    "import csv\n",
    "\n",
    "# using pandas \n",
    "df = pd.read_csv(\"FINAL_FROM_DF.csv\")\n",
    "\n",
    "# using Dask \n",
    "dask = dask.dataframe.read_csv(\"FINAL_FROM_DF.csv\")\n",
    "\n",
    "# using csv\n",
    "csv_file = open(\"FINAL_FROM_DF.csv\")\n",
    "data = csv.reader(csv_file, delimiter= \",\", quotechar= \"|\")\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:34:21.483327Z",
     "iopub.status.busy": "2021-08-24T19:34:21.482995Z",
     "iopub.status.idle": "2021-08-24T19:34:21.490797Z",
     "shell.execute_reply": "2021-08-24T19:34:21.489942Z",
     "shell.execute_reply.started": "2021-08-24T19:34:21.483298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['symbol',\n",
       " 'series',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'last',\n",
       " 'prevclose',\n",
       " 'tottrdqty',\n",
       " 'tottrdval',\n",
       " 'timestamp',\n",
       " 'totaltrades',\n",
       " 'isin']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning columns names \n",
    "u.clean_col_names(df)\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:34:22.743987Z",
     "iopub.status.busy": "2021-08-24T19:34:22.743641Z",
     "iopub.status.idle": "2021-08-24T19:34:44.403007Z",
     "shell.execute_reply": "2021-08-24T19:34:44.402331Z",
     "shell.execute_reply.started": "2021-08-24T19:34:22.743958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation test: PASS\n",
      "The file name is stocks.csv\n",
      "The delimiter used is ','\n",
      "The number of columns in the data is 13\n",
      "The data is 2GB in size.\n",
      "The columns for the data are: ['symbol', 'series', 'open', 'high', 'low', 'close', 'last', 'prevclose', 'tottrdqty', 'tottrdval', 'timestamp', 'totaltrades', 'isin']\n"
     ]
    }
   ],
   "source": [
    "col_val = u.col_val(df, conf_table)\n",
    "u.result(col_val, df, conf_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T19:41:37.225230Z",
     "iopub.status.busy": "2021-08-24T19:41:37.224876Z",
     "iopub.status.idle": "2021-08-24T19:41:37.250426Z",
     "shell.execute_reply": "2021-08-24T19:41:37.248893Z",
     "shell.execute_reply.started": "2021-08-24T19:41:37.225199Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(10).to_csv('new.gz', sep='|', compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
